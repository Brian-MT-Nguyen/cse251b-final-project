{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39357cfa",
   "metadata": {},
   "source": [
    "## Put all imports necessary here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be0f6a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e17a1ee",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4847f61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data's shape (10000, 50, 110, 6)\n",
      "test_data's shape (2100, 50, 50, 6)\n"
     ]
    }
   ],
   "source": [
    "# Load the training data\n",
    "train_file = np.load('train.npz')\n",
    "train_data = train_file['data']\n",
    "print(\"train_data's shape\", train_data.shape)\n",
    "\n",
    "# Load the testing data\n",
    "test_file = np.load('test_input.npz')\n",
    "test_data = test_file['data']\n",
    "print(\"test_data's shape\", test_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464d8a08",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da751e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data, is_train=True):\n",
    "    \"\"\"Extract ego vehicle's (agent 0) trajectories\"\"\"\n",
    "    if is_train:\n",
    "        X = data[:, 0, :50, :]  # (N, 50, 6) - First 50 timesteps\n",
    "        Y = data[:, 0, 50:, :2]  # (N, 60, 2) - Next 60 (x,y)\n",
    "    else:\n",
    "        X = data[:, 0, :, :]  # (N, 50, 6) - Test uses only 50 timesteps\n",
    "        Y = None\n",
    "    return X, Y\n",
    "\n",
    "X_train, Y_train = prepare_data(train_data)\n",
    "X_test, _ = prepare_data(test_data, is_train=False)\n",
    "\n",
    "# Normalize using training stats\n",
    "pos_mean, pos_std = X_train[..., :2].mean(), X_train[..., :2].std()\n",
    "X_train_norm = (X_train - pos_mean) / pos_std\n",
    "Y_train_norm = (Y_train - pos_mean) / pos_std\n",
    "X_test_norm = (X_test - pos_mean) / pos_std\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "train_dataset = TensorDataset(\n",
    "    torch.FloatTensor(X_train_norm), \n",
    "    torch.FloatTensor(Y_train_norm)\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4437de3c",
   "metadata": {},
   "source": [
    "## Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75c160d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajectoryMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(50*6, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 60*2)  # Predict all 60 timesteps\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        return self.net(x).view(-1, 60, 2)  # Reshape to (batch, 60, 2)\n",
    "\n",
    "model = TrajectoryMLP()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17b5c45",
   "metadata": {},
   "source": [
    "## Do Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96280878",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 157/157 [00:00<00:00, 361.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss: 0.0475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 157/157 [00:00<00:00, 631.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss: 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 157/157 [00:00<00:00, 654.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss: 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 157/157 [00:00<00:00, 639.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss: 0.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 157/157 [00:00<00:00, 624.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss: 0.0055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 157/157 [00:00<00:00, 624.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss: 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 157/157 [00:00<00:00, 616.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss: 0.0046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 157/157 [00:00<00:00, 609.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss: 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 157/157 [00:00<00:00, 606.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss: 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 157/157 [00:00<00:00, 600.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss: 0.0044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_X, batch_Y in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Avg Loss: {total_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a306ea3b",
   "metadata": {},
   "source": [
    "## Predict and Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f30e174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved! Example predictions:\n",
      "                 x            y\n",
      "index                          \n",
      "0      5446.548828  1525.442505\n",
      "1      5451.425293  1518.542847\n",
      "2      5454.622070  1513.448730\n",
      "3      5440.516602  1511.121094\n",
      "4      5441.444824  1482.686523\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_input = torch.FloatTensor(X_test_norm).to(device)\n",
    "    preds_norm = model(test_input).cpu().numpy()  # (2100, 60, 2)\n",
    "\n",
    "# Denormalize\n",
    "preds = preds_norm * pos_std + pos_mean\n",
    "\n",
    "# Create submission\n",
    "submission = preds.reshape(-1, 2)  # Flatten to (2100*60, 2)\n",
    "submission_df = pd.DataFrame(submission, columns=['x', 'y'])\n",
    "submission_df.index.name = 'index'\n",
    "submission_df.to_csv('submission.csv')\n",
    "\n",
    "print(\"Submission saved! Example predictions:\")\n",
    "print(submission_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
