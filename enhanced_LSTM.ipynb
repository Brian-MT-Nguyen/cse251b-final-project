{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39357cfa",
   "metadata": {},
   "source": [
    "## Put all imports necessary here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be0f6a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e17a1ee",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4847f61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data's shape (10000, 50, 110, 6)\n",
      "test_data's shape (2100, 50, 50, 6)\n"
     ]
    }
   ],
   "source": [
    "# Load the training data\n",
    "train_file = np.load('train.npz')\n",
    "train_data = train_file['data']\n",
    "print(\"train_data's shape\", train_data.shape)\n",
    "\n",
    "# Load the testing data\n",
    "test_file = np.load('test_input.npz')\n",
    "test_data = test_file['data']\n",
    "print(\"test_data's shape\", test_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464d8a08",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "da751e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhanced_normalize(data):\n",
    "    \"\"\"Normalize all features separately\"\"\"\n",
    "    means = data[..., :4].mean(axis=(0,1,2))  # x,y,vx,vy\n",
    "    stds = data[..., :4].std(axis=(0,1,2))\n",
    "    \n",
    "    # Normalize first 4 features\n",
    "    norm_data = data.copy()\n",
    "    norm_data[..., :4] = (data[..., :4] - means) / stds\n",
    "    \n",
    "    # Handle heading (wrap around for angles)\n",
    "    heading_mean = np.arctan2(np.sin(data[..., 4]).mean(), np.cos(data[..., 4]).mean())\n",
    "    norm_data[..., 4] = (data[..., 4] - heading_mean) / np.pi  # Normalize to [-1,1]\n",
    "    \n",
    "    return norm_data, (means, stds, heading_mean)\n",
    "\n",
    "# Normalize training data\n",
    "train_norm, norm_stats = enhanced_normalize(train_data)\n",
    "test_norm, _ = enhanced_normalize(test_data)\n",
    "\n",
    "# 2. Data Preparation\n",
    "def prepare_data(data, is_train=True):\n",
    "    X = data[:, 0, :50, :]  # (N, 50, 6)\n",
    "    if is_train:\n",
    "        Y = data[:, 0, 50:, :2]  # (N, 60, 2)\n",
    "    else:\n",
    "        Y = None\n",
    "    \n",
    "    # Reshape for LSTM\n",
    "    X = np.swapaxes(X, 0, 1)  # (50, N, 6)\n",
    "    if Y is not None:\n",
    "        Y = np.swapaxes(Y, 0, 1)  # (60, N, 2)\n",
    "    \n",
    "    return torch.FloatTensor(X), torch.FloatTensor(Y) if Y is not None else None\n",
    "\n",
    "X_train, Y_train = prepare_data(train_norm)\n",
    "X_test, _ = prepare_data(test_norm, is_train=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4437de3c",
   "metadata": {},
   "source": [
    "## Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "75c160d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedLSTM(nn.Module):\n",
    "    def __init__(self, input_size=6, hidden_size=256):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=3,\n",
    "            dropout=0.3,\n",
    "            batch_first=False\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, pred_steps=60):\n",
    "        # Process history\n",
    "        _, (h, c) = self.lstm(x)\n",
    "        \n",
    "        # Initialize with better features\n",
    "        last_state = torch.cat([\n",
    "            x[-1:, :, :2],  # Last position\n",
    "            x[-1:, :, 2:4],  # Last velocity\n",
    "            x[-1:, :, 4:]   # Last heading\n",
    "        ], dim=-1)\n",
    "        \n",
    "        predictions = []\n",
    "        for _ in range(pred_steps):\n",
    "            out, (h, c) = self.lstm(last_state, (h, c))\n",
    "            pred = self.fc(out)\n",
    "            predictions.append(pred)\n",
    "            \n",
    "            # Update with predicted position and maintained dynamics\n",
    "            new_state = torch.cat([\n",
    "                pred,\n",
    "                last_state[:, :, 2:4],  # Keep same velocity\n",
    "                last_state[:, :, 4:]    # Keep same heading\n",
    "            ], dim=-1)\n",
    "            last_state = new_state\n",
    "            \n",
    "        return torch.cat(predictions, dim=0)\n",
    "\n",
    "model = EnhancedLSTM()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17b5c45",
   "metadata": {},
   "source": [
    "## Do Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "96280878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.4999\n",
      "Epoch 2, Loss: 0.9747\n",
      "Epoch 3, Loss: 0.6345\n",
      "Epoch 4, Loss: 0.4982\n",
      "Epoch 5, Loss: 0.1059\n",
      "Epoch 6, Loss: 0.0312\n",
      "Epoch 7, Loss: 0.0131\n",
      "Epoch 8, Loss: 0.0181\n",
      "Epoch 9, Loss: 0.0089\n",
      "Epoch 10, Loss: 0.0081\n",
      "Epoch 11, Loss: 0.0065\n",
      "Epoch 12, Loss: 0.0123\n",
      "Epoch 13, Loss: 0.0057\n",
      "Epoch 14, Loss: 0.0056\n",
      "Epoch 15, Loss: 0.0069\n",
      "Epoch 16, Loss: 0.0045\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "train_dataset = TensorDataset(X_train.permute(1,0,2), Y_train.permute(1,0,2))\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x.permute(1,0,2).to(device), batch_y.permute(1,0,2).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Early stop to hopefully stop overfitting\n",
    "    if epoch_loss/len(train_loader) < 0.005:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a306ea3b",
   "metadata": {},
   "source": [
    "## Predict and Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8f30e174",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_preds = model(X_test.to(device)).cpu().numpy()  # (60, 2100, 2)\n",
    "\n",
    "# Denormalize only positions\n",
    "pos_mean, pos_std = norm_stats[0][:2], norm_stats[1][:2]\n",
    "test_preds = np.swapaxes(test_preds, 0, 1)  # (2100, 60, 2)\n",
    "test_preds = test_preds * pos_std + pos_mean\n",
    "\n",
    "# Create submission\n",
    "submission = test_preds.reshape(-1, 2)\n",
    "submission_df = pd.DataFrame(submission, columns=['x','y'])\n",
    "submission_df.index.name = 'index'\n",
    "submission_df.to_csv('enhanced_lstm_submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
